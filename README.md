COVID-19 ETL Pipeline

This project is an ETL (Extract, Transform, Load) pipeline built with PySpark, PostgreSQL, and Apache Superset to analyze COVID-19 data (2020â€“2025). It extracts raw data from CSV, transforms it into a clean structured format, and loads it into PostgreSQL for visualization in Superset.

ğŸš€ Features
	â€¢	Extracts COVID-19 dataset from local files.
	â€¢	Cleans, casts datatypes, and aggregates data with PySpark.
	â€¢	Loads processed data into PostgreSQL.
	â€¢	Visualizes data using Apache Superset with charts & dashboards.
	â€¢	Logging enabled for Extract, Transform, Load phases.

ğŸ“‚ Project Structure
ETL_project/
â”‚â”€â”€ extract/            # Extract raw dataset
â”‚   â””â”€â”€ execute.py
â”‚
â”‚â”€â”€ transform/          # Clean and transform data
â”‚   â””â”€â”€ execute.py
â”‚
â”‚â”€â”€ load/               # Load transformed data into PostgreSQL
â”‚   â””â”€â”€ execute.py
â”‚
â”‚â”€â”€ utility/            # Utility functions (logging, configs)
â”‚   â””â”€â”€ utility.py
â”‚
â”‚â”€â”€ .gitignore          # Ignore logs, JSON configs, cache
â”‚â”€â”€ requirements.txt    # Python dependencies
â”‚â”€â”€ README.md           # Documentation

ğŸ› ï¸ Requirements

1. Clone the repository
git clone https://github.com/your-username/ETL_project.git
cd ETL_project

2. Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate   # for macOS/Linux
venv\Scripts\activate      # for Windows

3.  Install dependencies
pip install -r requirements.txt

â–¶ï¸ Running the ETL Pipeline
1.	Run Extract:
python extract/execute.py

2.	Run Transform:
python transform/execute.py

3.	Run Load:
python load/execute.py
